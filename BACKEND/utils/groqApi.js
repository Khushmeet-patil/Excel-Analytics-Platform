// utils/groqApi.js
const axios = require('axios');
const dotenv = require('dotenv');

dotenv.config();

// Groq API configuration
const GROQ_API_KEY = process.env.GROQ_API_KEY;
const GROQ_API_URL = 'https://api.groq.com/openai/v1/chat/completions';
const GROQ_MODEL = 'llama3-70b-8192'; // Using Llama model as specified

/**
 * Generate AI response using Groq API
 * @param {Array} messages - Array of message objects with role and content
 * @param {Object} contextData - Additional context data (project info, file data, etc.)
 * @returns {Promise<Object>} - The AI response
 */
const generateAIResponse = async (messages, contextData = null) => {
  try {
    if (!GROQ_API_KEY) {
      throw new Error('Groq API key is not configured');
    }

    // Prepare system message with context if available
    let systemMessage = {
      role: 'system',
      content: 'You are an AI assistant specialized in analyzing Excel data and providing insights.'
    };

    // Add context information if available
    if (contextData) {
      let contextPrompt = 'You are an AI assistant specialized in analyzing Excel data and providing insights. ';
      
      if (contextData.project) {
        contextPrompt += `You are working with a project named "${contextData.project.name}". `;
        if (contextData.project.description) {
          contextPrompt += `Project description: ${contextData.project.description}. `;
        }
      }
      
      if (contextData.file) {
        contextPrompt += `You are analyzing a file named "${contextData.file.name}" of type ${contextData.file.fileType}. `;
        if (contextData.file.columns && contextData.file.columns.length > 0) {
          contextPrompt += `The file has the following columns: ${contextData.file.columns.map(col => col.name).join(', ')}. `;
        }
      }
      
      if (contextData.data) {
        contextPrompt += `Here's a sample of the data: ${JSON.stringify(contextData.data.slice(0, 5))}`;
      }
      
      systemMessage.content = contextPrompt;
    }

    // Prepare the full message array with system message first
    const fullMessages = [systemMessage, ...messages];

    // Make API request to Groq
    const response = await axios.post(
      GROQ_API_URL,
      {
        model: GROQ_MODEL,
        messages: fullMessages,
        temperature: 0.7,
        max_tokens: 2048
      },
      {
        headers: {
          'Authorization': `Bearer ${GROQ_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    return response.data;
  } catch (error) {
    console.error('Error calling Groq API:', error.message);
    throw new Error(`Failed to generate AI response: ${error.message}`);
  }
};

/**
 * Generate insights from file data
 * @param {Object} fileData - The file data to analyze
 * @param {Object} projectInfo - Project information for context
 * @returns {Promise<Object>} - The insights generated by AI
 */
const generateInsightsFromData = async (fileData, projectInfo = null) => {
  try {
    const dataPrompt = `Please analyze this data and provide insights: ${JSON.stringify(fileData.slice(0, 20))}`;
    
    const messages = [
      {
        role: 'user',
        content: dataPrompt
      }
    ];

    const contextData = {
      project: projectInfo,
      data: fileData
    };

    const response = await generateAIResponse(messages, contextData);
    
    return {
      content: response.choices[0].message.content,
      usage: response.usage
    };
  } catch (error) {
    console.error('Error generating insights:', error.message);
    throw new Error(`Failed to generate insights: ${error.message}`);
  }
};

module.exports = {
  generateAIResponse,
  generateInsightsFromData
};
